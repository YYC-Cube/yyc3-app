# üöÄ üöÄ YYC¬≥ÈÇÆ‰ª∂Âπ≥Âè∞ - ËøêÁª¥ÈÉ®ÁΩ≤‰∏éÁõëÊéßÊñáÊ°£

> **YYC¬≥ È°πÁõÆÊñáÊ°£**
> 
> @project YYC¬≥ Email Platform
> @type ÊäÄÊúØÊñáÊ°£
> @version 1.0.0
> @created 2025-12-08
> @updated 2025-12-08
> @author YYC¬≥ <admin@0379.email>
> @url https://github.com/YY-Nexus/0379-email-platform


## üìã ÈÉ®ÁΩ≤Ê¶ÇËø∞

**ÁõÆÊ†á**: ÊûÑÂª∫È´òÂèØÁî®„ÄÅÂèØÊâ©Â±ï„ÄÅÂÆâÂÖ®ÁöÑÈÇÆ‰ª∂ÊúçÂä°Âπ≥Âè∞  
**ÈÉ®ÁΩ≤ÁéØÂ¢É**: Docker + Kubernetes + Cloud Native  
**ÁõëÊéß‰ΩìÁ≥ª**: Prometheus + Grafana + ELK Stack  
**CI/CD**: GitHub Actions + ArgoCD  

### üéØ ÈÉ®ÁΩ≤Á≠ñÁï•

1. **Â§öÁéØÂ¢ÉÁÆ°ÁêÜ**: Development ‚Üí Staging ‚Üí Production
2. **ÂÆπÂô®ÂåñÈÉ®ÁΩ≤**: ÂÖ®Â∫îÁî®DockerÂåñÔºåÊîØÊåÅÂø´ÈÄüÊâ©ÂÆπ
3. **Ëá™Âä®ÂåñÈÉ®ÁΩ≤**: CI/CDÊµÅÊ∞¥Á∫øÔºåÈõ∂ÂÅúÊú∫Êõ¥Êñ∞
4. **Â§öÂèØÁî®Âå∫ÈÉ®ÁΩ≤**: ‰øùÈöúÈ´òÂèØÁî®ÊÄßÂíåÂÆπÁÅæËÉΩÂäõ
5. **ÁõëÊéßÂÖ®Ë¶ÜÁõñ**: Â∫îÁî®ÊåáÊ†á„ÄÅÁ≥ªÁªüÊåáÊ†á„ÄÅ‰∏öÂä°ÊåáÊ†á

## üê≥ ÂÆπÂô®ÂåñÈÉ®ÁΩ≤

### DockerfileËßÑËåÉ

#### ÂêéÁ´ØÊúçÂä°Dockerfile
```dockerfile
# backend/Dockerfile
# === Â§öÈò∂ÊÆµÊûÑÂª∫ ===
# ÊûÑÂª∫Èò∂ÊÆµ
FROM node:18-alpine AS builder

# ËÆæÁΩÆÂ∑•‰ΩúÁõÆÂΩï
WORKDIR /app

# Â§çÂà∂packageÊñá‰ª∂
COPY package*.json ./
RUN npm ci --only=production --silent

# Â§çÂà∂Ê∫ê‰ª£Á†Å
COPY . .

# ÁºñËØëTypeScript
RUN npm run build

# === Áîü‰∫ßÈò∂ÊÆµ ===
FROM node:18-alpine AS production

# ÂàõÂª∫ÈùûrootÁî®Êà∑
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

# ÂÆâË£ÖÁ≥ªÁªü‰æùËµñ
RUN apk add --no-cache \
    tini \
    dumb-init \
    curl \
    && rm -rf /var/cache/apk/*

WORKDIR /app

# Â§çÂà∂ÊûÑÂª∫‰∫ßÁâ©
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

# ÂÅ•Â∫∑Ê£ÄÊü•
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# ÂàáÊç¢Âà∞ÈùûrootÁî®Êà∑
USER nextjs

# Êö¥Èú≤Á´ØÂè£
EXPOSE 3000

# ‰ΩøÁî®tini‰Ωú‰∏∫ËøõÁ®ãÁÆ°ÁêÜÂô®
ENTRYPOINT ["tini", "--"]
CMD ["node", "dist/index.js"]
```

#### ÂâçÁ´ØÊúçÂä°Dockerfile
```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Â§çÂà∂‰æùËµñÊñá‰ª∂
COPY package*.json ./
RUN npm ci --silent

# Â§çÂà∂Ê∫ê‰ª£Á†Å
COPY . .

# ÊûÑÂª∫Â∫îÁî®
RUN npm run build

# === Áîü‰∫ßÈò∂ÊÆµ ===
FROM nginx:alpine AS production

# Â§çÂà∂Ëá™ÂÆö‰πânginxÈÖçÁΩÆ
COPY nginx.conf /etc/nginx/nginx.conf

# Â§çÂà∂ÊûÑÂª∫‰∫ßÁâ©
COPY --from=builder /app/.next /usr/share/nginx/html/.next
COPY --from=builder /app/public /usr/share/nginx/html/public

# ÂàõÂª∫ÈùûrootÁî®Êà∑
RUN addgroup -g 1001 -S nginx
RUN adduser -S nginx -u 1001

# ÂÅ•Â∫∑Ê£ÄÊü•
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:80/health || exit 1

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

#### NginxÈÖçÁΩÆ
```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Êó•ÂøóÊ†ºÂºè
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Âü∫Á°ÄÈÖçÁΩÆ
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;

    # ÂéãÁº©ÈÖçÁΩÆ
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # ‰∏äÊ∏∏ÊúçÂä°Âô®ÂÆö‰πâ
    upstream backend {
        least_conn;
        server backend-service-1:3000 max_fails=3 fail_timeout=30s;
        server backend-service-2:3000 max_fails=3 fail_timeout=30s;
        server backend-service-3:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # ‰∏ªÊúçÂä°Âô®ÈÖçÁΩÆ
    server {
        listen 80;
        server_name _;
        
        # Ê†πÁõÆÂΩï
        root /usr/share/nginx/html;
        index index.html index.htm;

        # ÂÅ•Â∫∑Ê£ÄÊü•Á´ØÁÇπ
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Next.js APIË∑ØÁî±‰ª£ÁêÜ
        location /api/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Ë∂ÖÊó∂ËÆæÁΩÆ
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # ÈùôÊÄÅÊñá‰ª∂ÁºìÂ≠ò
        location /_next/static/ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header X-Content-Type-Options nosniff;
        }

        location /static/ {
            expires 1y;
            add_header Cache-Control "public, immutable";
            add_header X-Content-Type-Options nosniff;
        }

        # ÂÆâÂÖ®Â§¥
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

        # ÂâçÁ´ØÂ∫îÁî®
        location / {
            try_files $uri $uri/ /index.html;
            
            # ÁºìÂ≠òÁ≠ñÁï•
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
            }
            
            location ~* \.html$ {
                expires -1;
                add_header Cache-Control "no-cache, no-store, must-revalidate";
            }
        }

        # ÈîôËØØÈ°µÈù¢
        error_page 404 /404.html;
        error_page 500 502 503 504 /50x.html;
        
        location = /50x.html {
            root /usr/share/nginx/html;
        }
    }

    # HTTPSÈÖçÁΩÆ (Áîü‰∫ßÁéØÂ¢É)
    server {
        listen 443 ssl http2;
        server_name email.example.com;

        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # HSTS
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload";

        # ÂåÖÂê´80Á´ØÂè£ÁöÑÈáçÂÆöÂêë
        location / {
            return 301 https://$server_name$request_uri;
        }
    }
}
```

### Docker ComposeÈÖçÁΩÆ

#### ÂºÄÂèëÁéØÂ¢É
```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  # PostgreSQLÊï∞ÊçÆÂ∫ì
  postgres:
    image: postgres:15-alpine
    container_name: email-postgres-dev
    environment:
      POSTGRES_DB: email_platform
      POSTGRES_USER: email_user
      POSTGRES_PASSWORD: dev_password
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      - email-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U email_user -d email_platform"]
      interval: 30s
      timeout: 10s
      retries: 3

  # RedisÁºìÂ≠ò
  redis:
    image: redis:7-alpine
    container_name: email-redis-dev
    command: redis-server --requirepass dev_redis_password --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - email-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 3s
      retries: 5

  # ÂêéÁ´ØAPIÊúçÂä°
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: email-backend-dev
    environment:
      NODE_ENV: development
      DATABASE_URL: postgresql://email_user:dev_password@postgres:5432/email_platform
      REDIS_URL: redis://:dev_redis_password@redis:6379
      JWT_SECRET: dev-jwt-secret-key
      SMTP_HOST: smtp.example.com
      SMTP_PORT: 587
      SMTP_USER: your-smtp-user
      SMTP_PASS: your-smtp-password
    volumes:
      - ./backend:/app
      - /app/node_modules
    ports:
      - "3001:3000"
    networks:
      - email-network
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ÂâçÁ´ØÂ∫îÁî®
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    container_name: email-frontend-dev
    environment:
      NEXT_PUBLIC_API_URL: http://localhost:3001
      NEXT_PUBLIC_WS_URL: ws://localhost:3001
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    networks:
      - email-network
    restart: unless-stopped
    depends_on:
      backend:
        condition: service_healthy

  # MailHogÈÇÆ‰ª∂ÊµãËØïÊúçÂä°
  mailhog:
    image: mailhog/mailhog:latest
    container_name: email-mailhog-dev
    ports:
      - "1025:1025"  # SMTPÊúçÂä°Âô®
      - "8025:8025"  # WebÁïåÈù¢
    networks:
      - email-network
    restart: unless-stopped

  # MinIOÂØπË±°Â≠òÂÇ®
  minio:
    image: minio/minio:latest
    container_name: email-minio-dev
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - email-network
    restart: unless-stopped

  # PrometheusÁõëÊéß
  prometheus:
    image: prom/prometheus:latest
    container_name: email-prometheus-dev
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - email-network
    restart: unless-stopped

  # GrafanaÁõëÊéßÈù¢Êùø
  grafana:
    image: grafana/grafana:latest
    container_name: email-grafana-dev
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    ports:
      - "3003:3000"
    networks:
      - email-network
    restart: unless-stopped
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  minio_data:
  prometheus_data:
  grafana_data:

networks:
  email-network:
    driver: bridge
```

#### Áîü‰∫ßÁéØÂ¢É
```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # PostgreSQL‰∏ª‰ªéÈõÜÁæ§
  postgres-master:
    image: postgres:15-alpine
    container_name: email-postgres-master
    environment:
      POSTGRES_DB: email_platform
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_REPLICATION_MODE: master
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_master_data:/var/lib/postgresql/data
      - ./scripts/postgres/replication.sql:/docker-entrypoint-initdb.d/replication.sql
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  postgres-replica:
    image: postgres:15-alpine
    container_name: email-postgres-replica
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGUSER: postgres
      POSTGRES_MASTER_SERVICE: postgres-master
      POSTGRES_REPLICATION_MODE: slave
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: ${POSTGRES_REPLICATION_PASSWORD}
    volumes:
      - postgres_replica_data:/var/lib/postgresql/data
    networks:
      - email-production
    restart: unless-stopped
    depends_on:
      - postgres-master
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # RedisÈõÜÁæ§
  redis-node-1:
    image: redis:7-alpine
    container_name: email-redis-1
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --cluster-announce-ip redis-node-1 --cluster-announce-port 6379 --cluster-announce-bus-port 16379
    volumes:
      - redis_1_data:/data
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M

  redis-node-2:
    image: redis:7-alpine
    container_name: email-redis-2
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --cluster-announce-ip redis-node-2 --cluster-announce-port 6379 --cluster-announce-bus-port 16379
    volumes:
      - redis_2_data:/data
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M

  redis-node-3:
    image: redis:7-alpine
    container_name: email-redis-3
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes --cluster-enabled yes --cluster-config-file nodes.conf --cluster-node-timeout 5000 --cluster-announce-ip redis-node-3 --cluster-announce-port 6379 --cluster-announce-bus-port 16379
    volumes:
      - redis_3_data:/data
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M

  # ÂêéÁ´ØAPIÊúçÂä°ÔºàÂ§öÂâØÊú¨Ôºâ
  backend-1:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: email-backend-1
    environment:
      NODE_ENV: production
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres-master:5432/email_platform
      REDIS_CLUSTER_NODES: redis-node-1:6379,redis-node-2:6379,redis-node-3:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      JWT_SECRET: ${JWT_SECRET}
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASS: ${SMTP_PASS}
    networks:
      - email-production
    restart: unless-stopped
    depends_on:
      - postgres-master
      - redis-node-1
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3

  # ÂâçÁ´ØÈùôÊÄÅËµÑÊ∫êÊúçÂä°
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: email-frontend
    environment:
      NGINX_HOST: ${DOMAIN}
      NGINX_PORT: 80
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # NginxË¥üËΩΩÂùáË°°Âô®
  nginx:
    image: nginx:alpine
    container_name: email-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - nginx_logs:/var/log/nginx
    networks:
      - email-production
    restart: unless-stopped
    depends_on:
      - frontend
      - backend-1

  # MinIOÂØπË±°Â≠òÂÇ®
  minio:
    image: minio/minio:latest
    container_name: email-minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Elasticsearch
  elasticsearch:
    image: elasticsearch:8.8.0
    container_name: email-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Logstash
  logstash:
    image: logstash:8.8.0
    container_name: email-logstash
    volumes:
      - ./elk/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline
      - nginx_logs:/var/log/nginx:ro
      - ./logs:/app/logs:ro
    networks:
      - email-production
    restart: unless-stopped
    depends_on:
      - elasticsearch

  # Kibana
  kibana:
    image: kibana:8.8.0
    container_name: email-kibana
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    networks:
      - email-production
    restart: unless-stopped
    depends_on:
      - elasticsearch

  # ÁõëÊéßÊúçÂä°
  prometheus:
    image: prom/prometheus:latest
    container_name: email-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.wal-compression'
    volumes:
      - ./monitoring/prometheus/prometheus.prod.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: email-grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    networks:
      - email-production
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M

volumes:
  postgres_master_data:
  postgres_replica_data:
  redis_1_data:
  redis_2_data:
  redis_3_data:
  minio_data:
  elasticsearch_data:
  prometheus_data:
  grafana_data:
  nginx_logs:

networks:
  email-production:
    driver: bridge
```

## üîß KubernetesÈÉ®ÁΩ≤

### ÂëΩÂêçÁ©∫Èó¥ÈÖçÁΩÆ
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: email-platform
  labels:
    name: email-platform
    environment: production
---
apiVersion: v1
kind: Namespace
metadata:
  name: email-platform-staging
  labels:
    name: email-platform-staging
    environment: staging
```

### ConfigMapÂíåSecret
```yaml
# k8s/configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: email-app-config
  namespace: email-platform
data:
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  SMTP_HOST: "smtp.example.com"
  SMTP_PORT: "587"
  REDIS_CLUSTER_NODES: "redis-node-1:6379,redis-node-2:6379,redis-node-3:6379"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: email-platform
data:
  nginx.conf: |
    events {
        worker_connections 1024;
    }
    
    http {
        upstream backend {
            least_conn;
            server backend-service.email-platform.svc.cluster.local:3000;
        }
        
        server {
            listen 80;
            server_name _;
            
            location /api/ {
                proxy_pass http://backend;
                proxy_set_header Host $host;
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                proxy_set_header X-Forwarded-Proto $scheme;
            }
            
            location / {
                try_files $uri $uri/ /index.html;
            }
        }
    }
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: email-platform
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "email_rules.yml"
    
    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
      
      - job_name: 'email-backend'
        static_configs:
          - targets: ['backend-service:3000']
        metrics_path: '/metrics'
        scrape_interval: 10s
      
      - job_name: 'node-exporter'
        static_configs:
          - targets: ['node-exporter:9100']
      
      - job_name: 'redis-exporter'
        static_configs:
          - targets: ['redis-exporter:9121']
      
      - job_name: 'postgres-exporter'
        static_configs:
          - targets: ['postgres-exporter:9187']
```

```yaml
# k8s/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: email-app-secrets
  namespace: email-platform
type: Opaque
data:
  # Base64ÁºñÁ†ÅÁöÑÂÄº
  POSTGRES_PASSWORD: cGFzc3dvcmQxMjM=  # password123
  REDIS_PASSWORD: cmVkaXNwYXNzd29yZA==  # redispassword
  JWT_SECRET: bXlzZWNyZXRrZXlqd3Q=  # mysecretkeyjwt
  SMTP_USER: bXlzbXRwdXNlcg==  # mysmtpuser
  SMTP_PASS: bXlzbXRwcGFzcw==  # mysmtppass
  MINIO_ROOT_USER: bWluaW9hZG1pbg==  # minioadmin
  MINIO_ROOT_PASSWORD: bWluaW9hZG1pbjEyMw==  # minioadmin123
---
apiVersion: v1
kind: Secret
metadata:
  name: ssl-certs
  namespace: email-platform
type: kubernetes.io/tls
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0...  # Base64ÁºñÁ†ÅÁöÑËØÅ‰π¶
  tls.key: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0...  # Base64ÁºñÁ†ÅÁöÑÁßÅÈí•
```

### PostgreSQLÈÉ®ÁΩ≤
```yaml
# k8s/postgresql.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-master
  namespace: email-platform
spec:
  serviceName: postgres-headless
  replicas: 1
  selector:
    matchLabels:
      app: postgres-master
  template:
    metadata:
      labels:
        app: postgres-master
    spec:
      containers:
      - name: postgres
        image: postgres:15-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "email_platform"
        - name: POSTGRES_USER
          value: "email_user"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: POSTGRES_PASSWORD
        - name: PGDATA
          value: "/var/lib/postgresql/data/pgdata"
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        - name: postgres-init
          mountPath: /docker-entrypoint-initdb.d
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - email_user
            - -d
            - email_platform
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - email_user
            - -d
            - email_platform
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: postgres-init
        configMap:
          name: postgres-init-scripts
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi
      storageClassName: fast-ssd
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-headless
  namespace: email-platform
spec:
  clusterIP: None
  selector:
    app: postgres-master
  ports:
  - port: 5432
    targetPort: 5432
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-service
  namespace: email-platform
spec:
  selector:
    app: postgres-master
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP
```

### RedisÈÉ®ÁΩ≤
```yaml
# k8s/redis.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: email-platform
spec:
  serviceName: redis-headless
  replicas: 3
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        - containerPort: 16379
        command:
        - redis-server
        - /etc/redis/redis.conf
        - --cluster-enabled
        - "yes"
        - --cluster-config-file
        - nodes.conf
        - --cluster-node-timeout
        - "5000"
        - --appendonly
        - "yes"
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: REDIS_PASSWORD
        volumeMounts:
        - name: redis-config
          mountPath: /etc/redis
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - --raw
            - -a
            - $(REDIS_PASSWORD)
            - incr
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - --raw
            - -a
            - $(REDIS_PASSWORD)
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
      storageClassName: fast-ssd
---
apiVersion: v1
kind: Service
metadata:
  name: redis-headless
  namespace: email-platform
spec:
  clusterIP: None
  selector:
    app: redis-cluster
  ports:
  - port: 6379
    targetPort: 6379
  - port: 16379
    targetPort: 16379
```

### ÂêéÁ´ØÊúçÂä°ÈÉ®ÁΩ≤
```yaml
# k8s/backend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-service
  namespace: email-platform
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: backend-service
  template:
    metadata:
      labels:
        app: backend-service
    spec:
      containers:
      - name: backend
        image: 0379-email-platform/backend:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          value: "postgresql://email_user:$(POSTGRES_PASSWORD)@postgres-service:5432/email_platform"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: POSTGRES_PASSWORD
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: REDIS_PASSWORD
        - name: REDIS_CLUSTER_NODES
          value: "redis-cluster-0.redis-headless.email-platform.svc.cluster.local:6379,redis-cluster-1.redis-headless.email-platform.svc.cluster.local:6379,redis-cluster-2.redis-headless.email-platform.svc.cluster.local:6379"
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: JWT_SECRET
        - name: SMTP_HOST
          valueFrom:
            configMapKeyRef:
              name: email-app-config
              key: SMTP_HOST
        - name: SMTP_USER
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: SMTP_USER
        - name: SMTP_PASS
          valueFrom:
            secretKeyRef:
              name: email-app-secrets
              key: SMTP_PASS
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
      imagePullSecrets:
      - name: registry-secret
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
  namespace: email-platform
spec:
  selector:
    app: backend-service
  ports:
  - port: 3000
    targetPort: 3000
  type: ClusterIP
```

### ÂâçÁ´ØÊúçÂä°ÈÉ®ÁΩ≤
```yaml
# k8s/frontend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-service
  namespace: email-platform
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend-service
  template:
    metadata:
      labels:
        app: frontend-service
    spec:
      containers:
      - name: frontend
        image: 0379-email-platform/frontend:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
  namespace: email-platform
spec:
  selector:
    app: frontend-service
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
```

### IngressÈÖçÁΩÆ
```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: email-platform-ingress
  namespace: email-platform
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - email.example.com
    secretName: email-platform-tls
  rules:
  - host: email.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
      - path: /api/
        pathType: Prefix
        backend:
          service:
            name: backend-service
            port:
              number: 3000
```

## üîÑ CI/CDÊµÅÊ∞¥Á∫ø

### GitHub ActionsÈÖçÁΩÆ
```yaml
# .github/workflows/deploy.yml
name: Deploy Email Platform

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: |
          backend/package-lock.json
          frontend/package-lock.json

    - name: Install backend dependencies
      run: |
        cd backend
        npm ci

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Run backend tests
      run: |
        cd backend
        npm test
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        JWT_SECRET: test-secret

    - name: Run frontend tests
      run: |
        cd frontend
        npm test

    - name: Run E2E tests
      run: |
        cd e2e
        npm ci
        npm run test
      env:
        BASE_URL: http://localhost:3000

    - name: Security audit
      run: |
        npm audit --audit-level moderate
      continue-on-error: true

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop'
    
    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push backend image
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        file: ./backend/Dockerfile
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build and push frontend image
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy-staging:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region us-west-2 --name email-platform-staging

    - name: Deploy to staging
      run: |
        # Êõ¥Êñ∞ÈïúÂÉèÊ†áÁ≠æ
        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:develop|g" k8s/backend.yaml
        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:develop|g" k8s/frontend.yaml
        
        # ÈÉ®ÁΩ≤Âà∞Kubernetes
        kubectl apply -f k8s/namespace.yaml
        kubectl apply -f k8s/configmaps.yaml
        kubectl apply -f k8s/secrets.yaml
        kubectl apply -f k8s/postgresql.yaml
        kubectl apply -f k8s/redis.yaml
        kubectl apply -f k8s/backend.yaml
        kubectl apply -f k8s/frontend.yaml
        kubectl apply -f k8s/ingress.yaml
        
        # Á≠âÂæÖÈÉ®ÁΩ≤ÂÆåÊàê
        kubectl rollout status deployment/backend-service -n email-platform-staging
        kubectl rollout status deployment/frontend-service -n email-platform-staging

    - name: Run smoke tests
      run: |
        # Á≠âÂæÖÊúçÂä°Â∞±Áª™
        sleep 30
        
        # ÂÅ•Â∫∑Ê£ÄÊü•
        kubectl get pods -n email-platform-staging
        
        # ËøêË°åÁÉüÈõæÊµãËØï
        curl -f http://staging.email.example.com/health || exit 1

  deploy-production:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.28.0'

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-2

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig --region us-west-2 --name email-platform-production

    - name: Create backup
      run: |
        # Êï∞ÊçÆÂ∫ìÂ§á‰ªΩ
        kubectl exec -n email-platform-production deployment/postgres-master -- pg_dump -U email_user email_platform > backup-$(date +%Y%m%d-%H%M%S).sql
        
        # Êñá‰ª∂Â§á‰ªΩ
        kubectl exec -n email-platform-production deployment/minio -- mc mirror minio/email-platform-files /backup/email-platform-files-$(date +%Y%m%d-%H%M%S)/

    - name: Deploy to production
      run: |
        # Êõ¥Êñ∞ÈïúÂÉèÊ†áÁ≠æ
        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:latest|g" k8s/backend.yaml
        sed -i "s|image: .*|image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:latest|g" k8s/frontend.yaml
        
        # ÊªöÂä®Êõ¥Êñ∞
        kubectl set image deployment/backend-service backend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:latest -n email-platform-production
        kubectl set image deployment/frontend-service frontend=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:latest -n email-platform-production
        
        # Á≠âÂæÖÊªöÂä®Êõ¥Êñ∞ÂÆåÊàê
        kubectl rollout status deployment/backend-service -n email-platform-production --timeout=600s
        kubectl rollout status deployment/frontend-service -n email-platform-production --timeout=600s

    - name: Verify deployment
      run: |
        # ÂÅ•Â∫∑Ê£ÄÊü•
        kubectl get pods -n email-platform-production
        
        # ÊúçÂä°Ê£ÄÊü•
        kubectl get svc -n email-platform-production
        
        # Á´ØÁÇπÊ£ÄÊü•
        curl -f https://email.example.com/api/health || exit 1

    - name: Send notification
      if: always()
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: |
          Email Platform deployment ${{ job.status }}
          Commit: ${{ github.sha }}
          Branch: ${{ github.ref_name }}
          Author: ${{ github.actor }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

## üìä ÁõëÊéß‰∏éÂëäË≠¶

### PrometheusÈÖçÁΩÆ
```yaml
# monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'email-platform'
    region: 'us-west-2'

rule_files:
  - "alert_rules.yml"
  - "recording_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'email-backend'
    static_configs:
      - targets: ['backend-service:3000']
    metrics_path: '/metrics'
    scrape_interval: 10s
    scrape_timeout: 5s

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 15s

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 15s

  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']
    scrape_interval: 15s

  - job_name: 'nginx-exporter'
    static_configs:
      - targets: ['nginx-exporter:9113']
    scrape_interval: 15s

  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

  - job_name: 'kubernetes-services'
    kubernetes_sd_configs:
      - role: service
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
```

### ÂëäË≠¶ËßÑÂàô
```yaml
# monitoring/prometheus/alert_rules.yml
groups:
  - name: email-platform.rules
    rules:
      # Á≥ªÁªüÁ∫ßÂëäË≠¶
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          team: platform
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Disk space is running low"
          description: "Disk space is below 10% on {{ $labels.instance }}"

      # Â∫îÁî®Á∫ßÂëäË≠¶
      - alert: BackendServiceDown
        expr: up{job="email-backend"} == 0
        for: 1m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Backend service is down"
          description: "Backend service has been down for more than 1 minute"

      - alert: HighBackendResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="email-backend"}[5m])) > 1
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High backend response time"
          description: "95th percentile response time is above 1 second"

      - alert: HighErrorRate
        expr: rate(http_requests_total{job="email-backend",status=~"5.."}[5m]) / rate(http_requests_total{job="email-backend"}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 5% for the last 5 minutes"

      # Êï∞ÊçÆÂ∫ìÂëäË≠¶
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          team: database
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database has been down for more than 1 minute"

      - alert: PostgreSQLTooManyConnections
        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "PostgreSQL too many connections"
          description: "PostgreSQL connections are above 80% of max connections"

      - alert: PostgreSQLSlowQueries
        expr: rate(pg_stat_database_blk_read_time[5m]) + rate(pg_stat_database_blk_write_time[5m]) > 100
        for: 5m
        labels:
          severity: warning
          team: database
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "Average query time is above 100ms"

      # RedisÂëäË≠¶
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          team: cache
        annotations:
          summary: "Redis is down"
          description: "Redis server has been down for more than 1 minute"

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          team: cache
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is above 90%"

      # ÈÇÆ‰ª∂ÊúçÂä°ÂëäË≠¶
      - alert: EmailQueueSizeHigh
        expr: email_queue_size > 1000
        for: 10m
        labels:
          severity: warning
          team: email
        annotations:
          summary: "Email queue size is high"
          description: "Email queue size is above 1000 for more than 10 minutes"

      - alert: EmailDeliveryRateLow
        expr: rate(emails_delivered_total[1h]) / rate(emails_sent_total[1h]) < 0.95
        for: 15m
        labels:
          severity: warning
          team: email
        annotations:
          summary: "Email delivery rate is low"
          description: "Email delivery rate is below 95% for the last hour"

      - alert: EmailBounceRateHigh
        expr: rate(emails_bounced_total[1h]) / rate(emails_sent_total[1h]) > 0.05
        for: 15m
        labels:
          severity: warning
          team: email
        annotations:
          summary: "Email bounce rate is high"
          description: "Email bounce rate is above 5% for the last hour"
```

### Grafana‰ª™Ë°®Êùø
```json
# monitoring/grafana/dashboards/email-platform-overview.json
{
  "dashboard": {
    "id": null,
    "title": "Email Platform Overview",
    "tags": ["email", "platform"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "System Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=~\"email-backend|postgres|redis\"}",
            "legendFormat": "{{instance}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{job=\"email-backend\"}[5m])",
            "legendFormat": "{{method}} {{status}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{job=\"email-backend\"}[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=\"email-backend\"}[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket{job=\"email-backend\"}[5m]))",
            "legendFormat": "99th percentile"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
      },
      {
        "id": 4,
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{job=\"email-backend\",status=~\"4..|5..\"}[5m]) / rate(http_requests_total{job=\"email-backend\"}[5m]) * 100",
            "legendFormat": "Error Rate %"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
      },
      {
        "id": 5,
        "title": "Email Statistics",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(emails_sent_total[5m])",
            "legendFormat": "Sent"
          },
          {
            "expr": "rate(emails_delivered_total[5m])",
            "legendFormat": "Delivered"
          },
          {
            "expr": "rate(emails_bounced_total[5m])",
            "legendFormat": "Bounced"
          },
          {
            "expr": "rate(emails_failed_total[5m])",
            "legendFormat": "Failed"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
      },
      {
        "id": 6,
        "title": "Database Connections",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_database_numbackends",
            "legendFormat": "{{datname}}"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24}
      },
      {
        "id": 7,
        "title": "Redis Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "redis_memory_used_bytes / redis_memory_max_bytes * 100",
            "legendFormat": "Memory Usage %"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24}
      }
    ],
    "time": {"from": "now-1h", "to": "now"},
    "refresh": "30s"
  }
}
```

### AlertManagerÈÖçÁΩÆ
```yaml
# monitoring/alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 5m
    
    - match:
        team: backend
      receiver: 'backend-team'
    
    - match:
        team: database
      receiver: 'database-team'
    
    - match:
        team: email
      receiver: 'email-team'

receivers:
  - name: 'default'
    email_configs:
      - to: 'ops@example.com'
        subject: '[Email Platform] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ range .Labels.SortedPairs }}{{ .Name }}: {{ .Value }}{{ end }}
          {{ end }}

  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@example.com'
        subject: '[CRITICAL] Email Platform Alert'
        body: |
          Critical Alert Detected!
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Time: {{ .StartsAt }}
          {{ end }}
    slack_configs:
      - api_url: 'https://hooks.slack.com/...'
        channel: '#alerts-critical'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
    webhook_configs:
      - url: 'http://pagerduty:9094/alert'
        send_resolved: true

  - name: 'backend-team'
    email_configs:
      - to: 'backend-team@example.com'
        subject: '[Backend] Email Platform Alert'

  - name: 'database-team'
    email_configs:
      - to: 'database-team@example.com'
        subject: '[Database] Email Platform Alert'

  - name: 'email-team'
    email_configs:
      - to: 'email-team@example.com'
        subject: '[Email] Email Platform Alert'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
```

## üîí ÂÆâÂÖ®ÈÖçÁΩÆ

### ÂÆπÂô®ÂÆâÂÖ®
```dockerfile
# ÂÆâÂÖ®Â¢ûÂº∫ÁöÑDockerfile
FROM node:18-alpine AS builder

# ÂàõÂª∫‰∏ìÁî®Áî®Êà∑ÁªÑ
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001

WORKDIR /app

# ÂÆâÂÖ®Êâ´Êèè
RUN apk add --no-cache \
    && rm -rf /var/cache/apk/* \
    && apk add --no-cache --virtual .build-deps \
    curl \
    && rm -rf /var/cache/apk/*

# ËÆæÁΩÆÊñá‰ª∂ÊùÉÈôê
COPY --chown=nextjs:nodejs . .

# ÊûÑÂª∫
RUN npm ci --only=production && npm cache clean --force

# Áîü‰∫ßÈò∂ÊÆµ
FROM node:18-alpine AS production

# ÂÆâÂÖ®Êõ¥Êñ∞
RUN apk update && apk upgrade && \
    apk add --no-cache \
    dumb-init \
    curl \
    && rm -rf /var/cache/apk/*

# ÂàõÂª∫ÈùûrootÁî®Êà∑
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

WORKDIR /app

# ÂÆâÂÖ®ÈÖçÁΩÆ
RUN chmod -R 755 /app && \
    chown -R nextjs:nodejs /app

# Â§çÂà∂ÊûÑÂª∫‰∫ßÁâ©
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist

# ÂÆâÂÖ®ËÆæÁΩÆ
USER nextjs
EXPOSE 3000

# ÂÅ•Â∫∑Ê£ÄÊü•
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# ‰ΩøÁî®dumb-init‰Ωú‰∏∫PID 1
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/index.js"]
```

### ÁΩëÁªúÂÆâÂÖ®Á≠ñÁï•
```yaml
# k8s/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: email-platform-network-policy
  namespace: email-platform
spec:
  podSelector:
    matchLabels:
      app: backend-service
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nginx
    ports:
    - protocol: TCP
      port: 3000
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 3000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

### RBACÊùÉÈôêÊéßÂà∂
```yaml
# k8s/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: email-platform-sa
  namespace: email-platform
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: email-platform
  name: email-platform-role
rules:
- apiGroups: [""]
  resources: ["secrets", "configmaps"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: email-platform-rolebinding
  namespace: email-platform
subjects:
- kind: ServiceAccount
  name: email-platform-sa
  namespace: email-platform
roleRef:
  kind: Role
  name: email-platform-role
  apiGroup: rbac.authorization.k8s.io
```

## üìà ÊÄßËÉΩ‰ºòÂåñ

### Ê∞¥Âπ≥PodËá™Âä®Êâ©Áº©ÂÆπ
```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: backend-hpa
  namespace: email-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
      - type: Pods
        value: 2
        periodSeconds: 60
```

### ÂûÇÁõ¥PodËá™Âä®Êâ©Áº©ÂÆπ
```yaml
# k8s/vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: backend-vpa
  namespace: email-platform
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: backend-service
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: backend
      maxAllowed:
        cpu: 2
        memory: 4Gi
      minAllowed:
        cpu: 100m
        memory: 128Mi
```

## üö® ÊïÖÈöúÊÅ¢Â§ç

### ÁÅæÈöæÊÅ¢Â§çËÆ°Âàí
```bash
#!/bin/bash
# disaster-recovery.sh

set -euo pipefail

# ÈÖçÁΩÆÂèòÈáè
BACKUP_BUCKET="s3://email-platform-backups"
KUBECONFIG_CONTEXT="email-platform-production"
DATABASE_SERVICE="postgres-service"
REDIS_SERVICE="redis-cluster"

echo "Starting disaster recovery process..."

# 1. È™åËØÅÂ§á‰ªΩÂèØÁî®ÊÄß
echo "1. Checking backup availability..."
aws s3 ls $BACKUP_BUCKET/latest/ || {
    echo "ERROR: No backup found in S3"
    exit 1
}

# 2. ÂàõÂª∫ÂΩìÂâçÁä∂ÊÄÅÂø´ÁÖß
echo "2. Creating snapshot of current state..."
kubectl --context=$KUBECONFIG_CONTEXT get all -n email-platform > current-state-$(date +%Y%m%d-%H%M%S).txt

# 3. ÂÅúÊ≠¢Â∫îÁî®ÊúçÂä°
echo "3. Stopping application services..."
kubectl --context=$KUBECONFIG_CONTEXT scale deployment backend-service --replicas=0 -n email-platform
kubectl --context=$KUBECONFIG_CONTEXT scale deployment frontend-service --replicas=0 -n email-platform

# 4. Â§á‰ªΩÂΩìÂâçÊï∞ÊçÆÂ∫ì
echo "4. Backing up current database..."
kubectl exec -n email-platform deployment/$DATABASE_SERVICE -- \
    pg_dump -U email_user email_platform > \
    emergency-backup-$(date +%Y%m%d-%H%M%S).sql

# 5. Ê∏ÖÁêÜÁé∞ÊúâÊï∞ÊçÆÔºàÂ¶ÇÊûúÈúÄË¶ÅÂÆåÂÖ®ÈáçÂª∫Ôºâ
echo "5. Cleaning existing data..."
kubectl delete pvc -n email-platform --all || true

# 6. ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì
echo "6. Restoring database from backup..."
LATEST_BACKUP=$(aws s3 ls $BACKUP_BUCKET/latest/ | tail -1 | awk '{print $4}')
aws s3 cp $BACKUP_BUCKET/latest/$LATEST_BACKUP - | \
    kubectl exec -i -n email-platform deployment/$DATABASE_SERVICE -- \
    psql -U email_user -d email_platform

# 7. ÊÅ¢Â§çRedisÊï∞ÊçÆ
echo "7. Restoring Redis data..."
aws s3 cp $BACKUP_BUCKET/latest/redis-dump.rdb - | \
    kubectl exec -i -n email-platform statefulset/redis-cluster -- \
    redis-cli --pipe

# 8. ÈáçÂêØÊúçÂä°
echo "8. Restarting services..."
kubectl --context=$KUBECONFIG_CONTEXT scale deployment backend-service --replicas=3 -n email-platform
kubectl --context=$KUBECONFIG_CONTEXT scale deployment frontend-service --replicas=2 -n email-platform

# 9. È™åËØÅÊÅ¢Â§ç
echo "9. Verifying recovery..."
sleep 30
kubectl --context=$KUBECONFIG_CONTEXT get pods -n email-platform
kubectl --context=$KUBECONFIG_CONTEXT get svc -n email-platform

# 10. ÂÅ•Â∫∑Ê£ÄÊü•
echo "10. Running health checks..."
curl -f https://email.example.com/api/health || {
    echo "ERROR: Health check failed"
    exit 1
}

echo "Disaster recovery completed successfully!"

# ÂèëÈÄÅÈÄöÁü•
curl -X POST "https://hooks.slack.com/..." \
    -H 'Content-type: application/json' \
    --data '{"text":"‚úÖ Email Platform disaster recovery completed successfully!"}'
```

### Â§á‰ªΩÁ≠ñÁï•
```yaml
# backup/backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: email-platform-backup
  namespace: email-platform
spec:
  schedule: "0 2 * * *"  # ÊØèÂ§©ÂáåÊô®2ÁÇπ
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: amazon/aws-cli:latest
            command:
            - /bin/bash
            - -c
            - |
              set -euo pipefail
              
              # Êï∞ÊçÆÂ∫ìÂ§á‰ªΩ
              echo "Starting database backup..."
              TIMESTAMP=$(date +%Y%m%d-%H%M%S